{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37064bit768efe16ff7b40448d6b4e5fef740258",
   "display_name": "Python 3.7.0 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow 2.1\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras = tf.keras\n",
    "layers = keras.layers\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "model_weight_path = './logs/fashion/'\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "train_count = x_train.shape[0]\n",
    "to_ds = tf.data.Dataset.from_tensor_slices\n",
    "train_ds = tf.data.Dataset.zip((to_ds(x_train), to_ds(y_train))).batch(100)\n",
    "test_ds = tf.data.Dataset.zip((to_ds(x_test), to_ds(y_test))).batch(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n\nTwo checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x0000021DFC7CF518> and <tensorflow.python.keras.layers.core.Flatten object at 0x0000021DFC7CF438>).\nModel: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nreshape_1 (Reshape)          (None, 28, 28, 1)         0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 13, 13, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 13, 13, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 11, 11, 32)        18464     \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 3872)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               495744    \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 516,138\nTrainable params: 516,138\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "x_test[0].shape\n",
    "model = keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(28, 28)),\n",
    "    layers.Reshape((28, 28, 1)),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "try:\n",
    "    model.load_weights(model_weight_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adagrad',\n",
    "    metrics=['acc']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train for 600 steps, validate for 100 steps\nEpoch 1/10\n600/600 [==============================] - 12s 20ms/step - loss: 0.6127 - acc: 0.7781 - val_loss: 0.5100 - val_acc: 0.8105\nEpoch 2/10\n600/600 [==============================] - 4s 7ms/step - loss: 0.4737 - acc: 0.8301 - val_loss: 0.4700 - val_acc: 0.8295\nEpoch 3/10\n600/600 [==============================] - 4s 7ms/step - loss: 0.4446 - acc: 0.8423 - val_loss: 0.4503 - val_acc: 0.8405\nEpoch 4/10\n600/600 [==============================] - 4s 7ms/step - loss: 0.4275 - acc: 0.8496 - val_loss: 0.4375 - val_acc: 0.8454\nEpoch 5/10\n600/600 [==============================] - 4s 7ms/step - loss: 0.4158 - acc: 0.8533 - val_loss: 0.4272 - val_acc: 0.8500\nEpoch 6/10\n600/600 [==============================] - 4s 7ms/step - loss: 0.4062 - acc: 0.8573 - val_loss: 0.4206 - val_acc: 0.8517\nEpoch 7/10\n600/600 [==============================] - 4s 7ms/step - loss: 0.3998 - acc: 0.8604 - val_loss: 0.4142 - val_acc: 0.8534\nEpoch 8/10\n600/600 [==============================] - 4s 7ms/step - loss: 0.3934 - acc: 0.8620 - val_loss: 0.4095 - val_acc: 0.8546\nEpoch 9/10\n600/600 [==============================] - 4s 7ms/step - loss: 0.3882 - acc: 0.8644 - val_loss: 0.4044 - val_acc: 0.8566\nEpoch 10/10\n600/600 [==============================] - 4s 7ms/step - loss: 0.3837 - acc: 0.8667 - val_loss: 0.4007 - val_acc: 0.8577\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x21f11353518>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.jpeg\n1.jpeg\n2.jpeg\n3.jpeg\n4.jpeg\n5.jpeg\n6.jpeg\n7.jpeg\n8.jpeg\n9.jpeg\n"
    }
   ],
   "source": [
    "file_path = './exam_fashion/'\n",
    "def read_img(x):\n",
    "    print(x)\n",
    "    im = tf.keras.preprocessing.image.load_img(file_path + x, color_mode=\"grayscale\", target_size=(28, 28))\n",
    "    ar = tf.keras.preprocessing.image.img_to_array(im) / 255.0\n",
    "    return ar.reshape((784,))\n",
    "ls = [read_img(x) for x in os.listdir(file_path)]\n",
    "ls_np = np.array(ls).reshape((10, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor([9 6 8 2 0 6 8 2 8 8], shape=(10,), dtype=int64)\n"
    }
   ],
   "source": [
    "pred = model.predict(ls_np)\n",
    "\n",
    "print(tf.math.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}